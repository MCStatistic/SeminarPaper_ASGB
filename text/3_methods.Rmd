---
output: pdf_document
---
```{r chunks, include=FALSE}
# Default Options - kann bei Gebrauch geändert werden
knitr::opts_chunk$set(
  echo = T # Whether to display code along with its results
  , eval = T # Whether to evaluate the code and include its results
  , results = "asis" # this at deafult is in end much more efficient
  , cache = F # Whether to cache results for future renders (efficient!)
  , warning = F # Whether to display errors
  , message = F # Whether to display messages
  , error = F # maybe turn on
  , tidy = F # Whether to reformat code in a tidy way when displaying it
  , fig.width = 6 # plot width at 6
  , fig.height = 4 # plot height at 4
  , fig.align = "left" # plot alignment center
)

options(xtable.comment = FALSE, scipen = 9999)

#devtools::install_github("ropensci/rcrossref")
# cat(rcrossref::cr_cn(dois = "10.1126/science.169.3946.635", format = "bibtex"))
# remedy::set_hotkeys()

pacman::p_load(tidyverse, gridExtra)

```


Im Folgenden soll die methodische Vorgehensweise erläutert werden, welche die Datenbeschaffung, die Klassifizierung sowie die anschließende Analyse beschreiben soll. Da es keinen Datensatz gibt, welcher sämtliche kleine Anfragen sowie deren thematische Klassifizierung enthält, mussten die Daten eigenständig erhoben und klassifiziert werden. Bei den kleinen Anfragen handelt es sich um Drucksachen des deutschen Bundestages, welche durch das *Dokumentations- und Informationssystem für Parlamentarische Vorgänge* öffentlich zugänglich sind [vgl. @dip21]. Diese Datenbank wird folglich als Datenquelle fungieren. Für sämtliche nachfolgend beschriebenen Schritte wurde die Programmiersprache R genutzt.[^1]

## Datenbeschaffung
Ausgehend der angeführten Punkte wurden sämtliche Drucksachen des 18. und 19. Bundestages automatisiert heruntergeladen.[^2] Da der 19. Bundestag nach wie vor besteht, musste ein Datum festgelegt werden, ab welchen keine weiteren Drucksachen mehr berücksichtigt werden.[^3] Für den 18. Bundestag wurden demnach 13.705 Drucksachen und für den 19. Bundestag (bis zum 31.12.2018) wurden 6.896 Drucksachen heruntergladen. Zusätzlich wurde die Trefferliste als CSV heruntergleaden, welche die Nummer der Drucksache sowie Titel und Datum der Drucksache enthält. Da jede Drucksache als PDF gespeichert wurde und ein standardisiertes Format aufweist, konnten die interessierten Bestandteile des Textes extrahiert werden.[^4] 

Zunächst wurde überprüft, ob es sich bei den Drucksachen um eine Anfrage handelt. Sofern es sich um keine Anfrage handelte, wurde die entsprechende Drucksache gelöscht. Anschließend wurden zudem die großen Anfragen ebenso gelöscht, da sich die Gesamtanzahl dieser über den gesamten Zeitraum auf unter 30 beläuft. Im 18. Bundestag wurden 3.951 kleine Anfragen gestellt und im 19. Bundestag 2.398. Der Datensatz beinhaltet somit 6349 kleine Anfragen. Anschließend wurde die Partei für jede kleine Anfrage ermittelt, welche stets am Ende des Titels steht. Zudem wurde der Inhalt jeder Anfrage extrahiert, welcher für die spätere Kategorisierung herangezogen wird. Der hierdurch erstellte Datensatz wurde mit der heruntergeladen CSV-Datei mit Titel und Datum ergänzt.

## Klassifizierung

Im Hinblick auf die Forschungsfrage müssen die kleinen Anfragen[^5] nach Themen klassifiziert werden. Dabei müssen die Themen zuvor klar definiert werden, welche für die Klassifizierung herangezogen werden sollen. Hierbei soll sich verstärkt an der Arbeit von Baumgartner, Jones und Wilkerson orientiert werden, welche für die USA und der dortigen nationalen Politik ein Kodiersystem erstellt haben [vgl. @baumgartner2006comparative 970]. Neben dem Kodiersystem, welches für die US-Politik erstellt wurde, exisitert eine neuere Version, welches allgemeine Kodierrichtlinien beinhaltet [vgl. @cap]. Einerseits kann das Kodiersystem leicht auf verschiedene Länder angewendet werden. Andererseits ergibt sich durch die Verwendung dieses Kodiersystems die Möglichkeit der Vergleichbarkeit mit anderen Ländern, was jedoch in dieser Arbeit nicht näher von Interesse ist [vgl. @john2006policy 983].

Anhand dieses Kodierungssystems werden die kleinen Anfragen in dieser Arbeit klassifiziert. Dabei enthält das Kodiersystem 21 Hauptthemen und 220 Subthemen. Zwischen den Subthemen wird bei der nachfolgenden Klassifizierung jedoch nicht differenziert. Diese Entscheidung ergibt sich aus zwei Gründen. Zum einen stellen die Hauptthemen bereits eine ausreichende Differenzierung zur Beantwortung der Forschungsfrage dar, wodurch eine zusätzliche Differenzierung zwischen den Subthemen zunächst keinen Mehrwert bringen würde. Zum anderen ist eine derart detaillierte Klassifizierung hinsichtlich der methodischen Vorgehensweise schwer zu realisieren, da es für einige der 220 Subthemen zu wenig Anfragen gibt. Eine Übersetzung der Kodierung ist im Anhang in Tabelle \ref{TabCodeBook} enthalten. Die Tabelle enthält die Hauptthemen sowie deren Subthemen. Ebenso sind in der Tabelle die Wörter enthalten, welche für den ersten Schritt der Klassifizierung herangezogen werden.

Die Klassifizierung der Anfragen erfolgt in zwei Schritten. Im ersten Schritt werden diese anhand von Wörtern klassifiziert und anschließend erfolgt eine Validierung dieser Klassifizierung. Im zweiten Schritt erfolgt eine Klassifizierung der Anfragen, die nicht durch den ersten Schritt klassifiziert werden konnten. Hierfür werden zwei Verfahren des Supervised Machine Learnings verwendet. Auf diese beiden Schritte wird im folgenden detailliert eingegangen.

\newpage

### Klassifizierung mittels Wörter

Anhand der Subthemen wurden für jedes Haupthema Wörter identifiziert, welche ausschließlich auf das jeweilige Haupthema zutreffen und sich thematisch von den übrigen Hauptthemen[^6] klar abgrenzen sollten. Dabei wurden die Wörter unter anderem auch durch das Querlesen einiger Anfragen ermittelt. Um mit Hilfe der Wörter eine zuverlässige Klassifizierung zu ermöglichen, wurde bei diesem Schritt lediglich der Titel der jeweiligen Anfrage herangezogen. Einerseits fungiert der Titel als eine Beschreibung des Inahlts, wodurch dieser entsprechend klar und prägnant formuliert sein muss. Daraus sollte sich eine hohe Wahrscheinlichkeit ergeben, dass hierbei ein Begriff enthalten ist, welcher auf das entsprechende Thema zu verorten ist. Andererseits ist davon auszugehen, dass im Inhalt der Anfrage ein Bezug zu anderen Themen vorkommen kann. Eine derartige Klassifizierung anhand der Inhalte würde folglich zu einem tendenziell unzuverlässigem Ergebnis führen.

Da im zweiten Schritt die bereits klassifizierten Anfragen als Grundlage dienen, muss diese entsprechend valide sein. Daher muss die soeben beschriebene Klassifizierung validiert werden. Dabei wird zunächst überprüft, ob Anfragen mittels der verwendeten Klassifizierung zu mehreren Themen zugeordnet werden könnten. Anschließend müssen diese identifizierten Anfragen händisch klassifiziert werden. Zusätzlich werden die Anfragen, welche nur einem Thema zugeordnet werden, ebenso überprüft. Auf diese Weise soll eine hohe Validität der Klassifizierung gewährleistet werden.

### Supervised Machine Learning

Durch die Klassifizierung mittels themenspezifischer Wörter können leider nicht alle Anfragen klassifiziert werden, wodurch ein weiterer Schritt notwendig sein wird. Ausgehend der klassifizierten Anfragen ergibt sich die Möglichkeit Methoden des Supervised Machine Learnings heranzuziehen. Dabei sollen zwei Klassifikationsverfahren verwendet werden. Hierbei handelt es sich um den Klassifikator *Radnom Forest* und um das Klassifikationsverfahren mittels einer *Support Vector Machine*. Diese beiden Methoden sollen zunächst beschrieben werden.

Ein Random Forest wird nach Breiman [-@breiman2001random] wie folgt definiert:

> Ein Random Forest ist ein Klassifikator, welcher aus einer Menge von *Tree*-strukturierten Klassifikatoren besteht {$h(\textbf{x}, \Theta_{k}), k = 1,...$}. Dabei handelt es sich bei {$\Theta_{k}$} um unabhängige zufällige Vektoren, welche eine identische Verteilung aufweisen. Jeder *Tree* gibt dabei eine Stimme für die beliebteste Klasse für \textbf{x} ab [vgl. @breiman2001random 6].

\newpage

Der Algorithmus, welcher beim Random Forest zum Einsatz kommt, kann dabei wie folgt beschrieben werden [vgl. @liaw2002classification 18; vgl. @friedman2017elements 588]:

1. Aus dem Datensatz werden $n_{tree}$ Samples mittels Bootstrap gezogen.

2. Für jedes dieser Bootstrap-Samples wird ein *unprunted Tree* erstellt.[^7] Für die Erstellung der *Trees* wird der Gini Index verwendet, wobei $T$ das Training Set, $C_{i}$ die Klassen und $f(C_{i}, T)/|T|$ die Wahrscheinlichkeit, dass ein Fall zu der Klasse $C_{i}$ gehört, darstellt [vgl. @pal2005random 218; vgl. @chan2008evaluation 3002]: 
$$G = \sum \displaystyle\sum_{j \neq i}(f(C_{i}, T)/|T|)(f(C_{j}, T)/|T|)$$

3. Abschließend können mit einem solchen trainiertem Modell neue Daten mittels Aggregierung den Vorhersagen der einzelnen $n_{tree}$ *Trees* klassifiziert werden. Wenn $\hat{C}_{b}(x)$ die Klassenvorhersage des *b*ten Random Forest Tree ist, so ist $\hat{C}_{rf}^{B}(x) = \text{Mehrheit der Stimmen}$ {$\hat{C}_{b}(x)$}$_{1}^{B}$.



Definition von Support Vector Machines...welche Kriterien muss eine Support Vector Machine erfüllen?

Geschichte: Ursprünglich für binäre Klassen entwickelt -> heutzutage jedoch auch multiclass möglich

[^1]: Der Code für alle Auswertungen der Hausarbeit ist auf GitHub unter https://github.com/MCStatistic/SeminarPaper_ASGB einsehbar.
[^2]: Hierfür wurde eine Funktion in R geschrieben, mit welcher jede Drucksache als PDF vom offiziellen Server heruntergeladen wurde. Die Dateien wurden dabei unter der Nummer der Drucksache sowie des jeweiligen Bundestags gespeichert um so eine klare Zuordnung gewährleisten zu können.
[^3]: Für den 18. Bundestag beläuft sich der Zeitraum vom 22. Oktober 2013 bis zum 24. Oktober 2017. Aufgrund der durchzuführenden Auswertungen wurde der zu analysierende Zeitraum für den 19. Bundestag vom 24. Oktober 2017 bis zum 31. Dezember 2018 festgelegt. 
[^4]: Hierfür wurde das Package *pdftools* [vgl. @pdftools] genutzt.
[^5]: Da die großen Anfragen in dieser Arbeit nicht berücksichtigt werden, wird nachfolgend zwecks der Lesbarkeit von *Anfragen* geschrieben. Dieser Begriff wird in dieser Arbeit als äquivalent zu *kleinen Anfragen* genutzt.
[^6]: Da keine Differenzierung zwischen den Subthemen erfolgt und nachfolgend nur noch eine Differenzierung zwischen den Hauptthemen relevant ist, wird ab sofort nur noch von Themen geschrieben. Die Begriffe *Hauptthema* und *Thema* werden in dieser Arbeit daher äquivalent genutzt.
[^7]: Um ein Overfitting bei Decision Trees zu vermeiden, wird oftmals die Methodik des *Prunings* verwendet [siehe hierzu u.a. @bradford1998pruning; @mingers1989empirical; @mehta1995mdl]. Dies ist beim Random Forest jedoch nicht erforderlich, da durch das Bootstrapping (oder auch *Bagging*) der Fehler bereits signifikant reduziert wird [siehe hierzu @breiman1996decision; @prasad2006newer 184]. Die Gefahr eines Overfittings ist bei einem Random Forest daher kein Problem [vgl. @breiman2001random].


\begin{table}[ht]
\centering
\caption{Klassenfehler nach $n_{tree}$ (Random Forest)}
\begin{tabular}{rllllr}
  \hline
 & Klasse & Fehler $RF_{200}$ & Fehler $RF_{500}$ & Fehler $RF_{1500}$ & Anzahl \\ 
  \hline
1 & Gesetz \& Kriminalität & 5.88\% & 5.64\% & 5.88\% & 535 \\ 
  2 & Transport & 9.59\% & 9.59\% & 9.96\% & 348 \\ 
  3 & Verteidigung & 10.24\% & 9.64\% & 9.04\% & 206 \\ 
  4 & Einwanderung & 12.35\% & 9.96\% & 11.95\% & 347 \\ 
  5 & Außenhandel & 15.38\% & 13.46\% & 14.42\% & 137 \\ 
  6 & Gesundheit & 21.55\% & 19.83\% & 18.97\% & 159 \\ 
  7 & Energie & 27.91\% & 25.58\% & 25.58\% & 167 \\ 
  8 & Arbeit & 28.95\% & 27.63\% & 31.58\% & 114 \\ 
  9 & Soziale Wohlfahrt & 38.71\% & 29.03\% & 27.96\% & 121 \\ 
  10 & Umwelt & 40.4\% & 36.42\% & 33.11\% & 197 \\ 
  11 & Makroökonomie & 42.42\% & 41.41\% & 41.41\% & 135 \\ 
  12 & Bildung & 53.66\% & 58.54\% & 56.1\% &  50 \\ 
  13 & Technologie & 61.22\% & 61.22\% & 59.18\% & 123 \\ 
  14 & Int. Angelegenheiten & 66.39\% & 67.21\% & 68.03\% & 170 \\ 
  15 & Regierungsoperationen & 82.35\% & 73.53\% & 73.53\% &  47 \\ 
  16 & Binnenhandel & 84.31\% & 78.43\% & 84.31\% &  71 \\ 
  17 & Wohnungsbau & 91.67\% & 91.67\% & 95.83\% &  27 \\ 
  18 & Agrarwirtschaft & 91.89\% & 94.59\% & 94.59\% &  51 \\ 
  19 & Bürgerrechte & 100\% & 100\% & 100\% &  42 \\ 
   \hline
\end{tabular}
\end{table}



\begin{table}[ht]
\centering
\begin{tabular}{lllllllll}
$p$   & \multicolumn{2}{c}{$RF_{200}$} & \multicolumn{2}{c}{$RF_{500}$} & \multicolumn{2}{c}{$RF_{1500}$} & \multicolumn{2}{c}{$SVM$} \\
   \hline
    & Richtig      & Anteil      & Richtig      & Anteil      & Richtig       & Anteil      & Richtig     & Anteil    \\
   \hline
0.3 &              &             &              &             &               &             &             &           \\
0.4 &              &             &              &             &               &             &             &           \\
0.5 &              &             &              &             &               &             &             &           \\
0.6 &              &             &              &             &               &             &             &           \\
0.7 &              &             &              &             &               &             &             &           \\
0.8 &              &             &              &             &               &             &             &           \\
0.9 &              &             &              &             &               &             &             &          \\
   \hline
\end{tabular}
\end{table}