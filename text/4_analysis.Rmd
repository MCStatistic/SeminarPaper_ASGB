---
output: pdf_document
---

## Klassifikation

Durch die Wortklassifizierung konnten 2726 Anfragen eindeutig klassifiziert werden. Weitere 253 Anfragen konnten durch die Wortklassifizierung zu 2 oder 3 Themen zugeordnet werden. Diese Anfragen wurden manuell richtig klassifiziert. Darüber hinaus wurden die Anfragen, welche durch die Wortklassifizierung nur einem Thema zugeordnet werden konnten, überprüft und bei wenigen Fällen korrigiert. Anschließend wurden weitere wenige Anfragen manuell kategorisiert um die Datengrundlage für die nachfolgenden Schritte der Kategorisierung weiter vergößern zu können. Auf diese Weise wurden 3047 der insgesamt 6349 Anfragen kategorisiert. In Abbildung \ref{word_classification} ist die Verteilung der Themen ersichtlich.

\begin{figure}[!h]
	\caption{Verteilung der Themen nach Wortklassifikation}
	\label{word_classification}
	\centering
	\includegraphics[width=\textwidth]{images/themen_gesamt_manual_matching_test.png}
	\caption*{\scriptsize }
\end{figure}

Dabei wird ersichtlich, dass die Themen *Gesetz & Kriminalität*, *Einwanderung* und *Transport* jeweils einen Anteil von mindestens 10% der klassifizierten Themen aufweisen. Gleichzeitig liegen Themen wie *Wohnungsbau*, *Bürgerrechte* und *Regierungsoperationen* vor, welche jeweils nur einen Anteil von 0,6% bis gut 2,1% ausmachen. Diese Form der ungleichen Verteilung der Themenanteile kann bei den nachfolgenden Klassifikationsschritten unter Umständen dafür sorgen, dass die Themen unterschiedlich gut klassifiziert werden können.

Bevor eine Klassfikation anhand aller bereits klassifizierten Anfragen umgesetzt wird, soll zunächst die Performance beider Klassifikationsverfahren untersucht werden. Einerseits können auf diese Weise wichtige Paramter der jewiligen Modelle optimiert werden. Andererseits können so spezifische Grenzwerte festgelegt werden, die für eine zuverlässige Klassifizierung notwendig sind. Hierfür wurden mittels der 3047 klassifizierten Anfragen ein Testdatensatz erstellt, wobei 2300 dieser Anfragen für das Training der Modelle verwendet wurden und die übrigen 747 Anfragen zur Überprüfung genutzt wurden. Diese Einteilung erfolgte mit vorheriger Randomisierung des erstellten Testdatensatzes. 

Da für Random Forest und Support Vector Machines jeweils Klassenwahrscheinlichkeiten berechnet werden, ist es möglich diese als Grenzwert heranziehen zu können. Bei einem hohen Grenzwert steigt zwar die Zuverlässigkeit der Klassifikation, jedoch sinkt ebenso der gesamte Anteil an klassifizierten Anfragen. In Tabelle \ref{kat_rf_svm} ist für jedes Modell der Anteil der richtig klassifizierten Anfragen sowie der Gesamtanteil der klassifizierten Anfragen ersichtlich. So zeigen sich keine bedeutenden Unterschiede hinsichtlich der genutzten Anzahl an *Trees* bei Random Forest. Für die Support Vector Machines wurden unterschiedliche C-Paramter getestet, wobei ein Wert von 10 die beste Performance erzielt hat (vgl. Abbildung \ref{c_values}).

\begin{table}[ht]
\centering
\caption{Richtig kategorisierte Anfragen und Anteil der Klassifikationen}
\label{kat_rf_svm}
\begin{tabular}{lllllllll}
$p$   & \multicolumn{2}{c}{$RF_{200}$} & \multicolumn{2}{c}{$RF_{500}$} & \multicolumn{2}{c}{$RF_{1500}$} & \multicolumn{2}{c}{$SVM_{C = 10}$} \\
   \hline
    & Richtig      & Anteil      & Richtig     & Anteil      & Richtig       & Anteil      & Richtig     & Anteil    \\
   \hline
 0.3 &   83,89    &    74,83  &    84,96    &   73,89   &   85,08     &   72,69   &  80,91   &   76,45  \\
 0.4 &   90,07    &    58,00  &    89,47    &   58,50   &   90,42     &   57,29   &  85,54   &   64,79  \\
 0.5 &   94,21    &    41,63  &    93,08    &   42,57   &   93,13     &   42,84   &  88,30   &   52,61  \\
 0.6 &   97,73    &    29,45  &    97,33    &   30,12   &   96,77     &   29,05   &  89,02   &   46,32  \\
 0.7 &   100      &    19,54  &    99,33    &   19,95   &   100       &   19,14   &  91,75   &   40,56 \\
 0.8 &   100      &    13,12  &    100      &   13,38   &   100       &   12,58   &  92,68   &   32,93  \\
 0.9 &   100      &     9,77  &    100      &    9,91   &   100       &    9,91   &  95,43   &   23,43  \\
 \hline
mean   & 95,40    &   34,56   &    94,73    &   36,37   &   95,06     &   34,79   &  89,09   &   48,16  \\
  \hline
\end{tabular}
\caption*{\scriptsize Anmerkung: Angaben in Prozent; $p$ stellt den Cutt Off für die Klassenwahrscheinlichkeit dar}
\end{table}

Insgesamt schneidet Random Forest hinsichtlich der Zuverlässigkeit sowie dem Anteil klassifizierter Anfragen sichtlich besser ab. Bereits ab einer Klassenwahrscheinlichkeit von $p = 0.4$ können 58% der Anfragen klassifiziert werden, wovon widerum 90% richtig klassifiziert sind. Um die selbe Zuverlässigkeit wie bei Random Forest zu erzielen, muss man die erforderliche Klassenwahrscheinlichkeit bei Support Vector Machines auf mindestens $p = 0.7$ festlegen. Dabei werden jedoch weniger Anfragen klassifiziert (40,56% gegenüber 58%). In Anbetracht dieser Ergebnisse wird für sämtliche nachfolgenden Modellierungen der C-Parameter auf 10 und *ntree* auf 200 festgelegt. 

Da die Klassenwahrscheinlichkeiten herangezogen werden um eine möglichst zuverlässige Klassifikation zu ermöglichen, soll nun betrachtet werden wie die Klassenwahrscheinlichkeiten bezüglich der einzelnen Themen aussieht. In Abbildung \ref{probs_test} sind sämtliche Klassenwahrscheinlichkeiten für Random Forest und Support Vector Machines ersichtlich. 

\begin{figure}[!h]
	\caption{Klassenwahrscheinlichkeiten (Testklassifikation)}
	\label{probs_test}
	\centering
	\includegraphics[width=\textwidth]{images/rf_svm_prob_boxplot_2.png}
	\caption*{\scriptsize Anmerkung: ntree = 200; C-Paramter = 10}
\end{figure}

Dabei zeigt sich, dass Random Forest bei einzelnen Themen schlechter abschneidet wie Support Vector Machines. So liegen für die Themen *Wohnungsbau* und *Bürgerrechte* 

Klassenwahrscheinlichkeiten für vollständige Klassifikation (Apendix, da kaum Unterschiede mit Testklassifikation...)

\begin{figure}[!h]
	\caption{Klassenwahrscheinlichkeiten (vollständige Klassifikation)}
	\label{probs_real}
	\centering
	\includegraphics[width=\textwidth]{images/prob_boxplot_real_mod_2.png}
	\caption*{\scriptsize }
\end{figure}

## Deskriptive Analyse

Darstellung der Anfragen nach Partei
\begin{figure}[!h]
	\caption{Anzahl gestellter Anfragen nach Partei}
	\label{anfragen_count}
	\centering
	\includegraphics[width=\textwidth]{images/AnfragenPartei_18_19_complete.png}
	\caption*{\scriptsize Anmerkung: Anzahl der kleinen Anfragen nach Jahr und Legislaturperiode}
\end{figure}

## Sentiment Analyse

