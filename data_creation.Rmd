---
title: "Data Wrangling"
author: "Marlon Schumacher"
date: "19 11 2018"
output: html_document
---

## Source of Data

[DIP (Dokumentations- und Informationssystem für Parlamentarische Vorgänge)](https://dipbt.bundestag.de/dip21.web/bt)

## URL's 19. BT

Last document of the 19. Bundestag
http://dipbt.bundestag.de/dip21/btd/19/000/1900001.pdf

First Document of the 19. Bundestag (Update is comming)
http://dipbt.bundestag.de/dip21/btd/19/057/1905799.pdf

## loading packages
```{r}
# just use pacman, it's delicous!
library(pacman)
p_load(magrittr, dplyr, stringr, downloader, purrr, pdftools, 
       glue, tm, janeaustenr, tidytext, corpus)
```

## creating URL's for each PDF
```{r}
# short code for creating all 5800 URL's (19. BTD)
# rep() replicates the object n-times
base_19 <- rep("http://dipbt.bundestag.de/dip21/btd/19/0", each = 6700) 

# code explaining: replicate the character ".pdf" 5800 times
end_19 <- rep(".pdf", each = 6700)
mid_19 <- rep("/190", each = 6700)

# first step: creating a vector with the values from 00 up to 57 as characters
# second step: creating a vector where each value is replicated 100 times
# code exp: create a vector with the values of 00 to 57, all numbers
#           should be 2 digit long (defined by "%02.0f") and should be
#           defined as characters. Then take this vector and replicate it 100 times
first_19 <- as.character(sprintf("%02d", 00:66)) %>% 
  rep(each = 100) 

# creating a vector which includes the values 0000 up to 5799
# important: sprintf() is used for the 4-digit format
second_19 <- as.character(sprintf("%04d", 0000:6699))

# code exp: take all the vectors and combine these vectors with the function str_c()
#           sep = "" -> there is no seperation, otherwise it would be not a functonal url
urls_19 <- str_c(base_19, first_19, mid_19, second_19, end_19, 
              sep = "")

# checking url
head(urls_19, 2)
tail(urls_19, 2)

# checking length
length(urls_19)

# deleting the first link because theres no content
urls_19 <- urls_19[!urls_19 == "http://dipbt.bundestag.de/dip21/btd/19/000/1900000.pdf"]
tail(urls_19, 50)

# checking length again
length(urls_19)

# creating file-path for each link
path_19 <- paste("./19_btd/", basename(urls_19), sep = "")
length(path_19)
```

## Creating URL's for the 18. BTD

Last document of the 18. Bundestag
http://dipbt.bundestag.de/dip21/btd/18/137/1813705.pdf

First Document of the 18. Bundestag
http://dipbt.bundestag.de/dip21/btd/18/000/1800001.pdf

Documents 13700 up to 13705 doesn't include any type of document which is of interest

```{r}
# static body
# IMPRTANT: check/validate the links for the 18 BDT!
base_18 <- rep("http://dipbt.bundestag.de/dip21/btd/18/", each = 13700) 
end_18 <- rep(".pdf", each = 13700)
mid_18 <- rep("/18", each = 13700)

# dynamic body
first_18 <- as.character(sprintf("%03d", 000:136)) %>% 
  rep(each = 100)

second_18 <- as.character(sprintf("%05d", 00000:13699))

# combine all url-elements
urls_18 <- str_c(base_18, first_18, mid_18, second_18, end_18, spe = "")

# checking the URLs
head(urls_18, 2)
tail(urls_18, 2)

# checking length
length(urls_18)

# deleting first URL because there is no content
urls_18 <- urls_18[!urls_18 == "http://dipbt.bundestag.de/dip21/btd/18/000/1800000.pdf"]

# checking length again
length(urls_18)

# creating file-path for each link
path_18 <- paste("./18_btd/", basename(urls_18), sep = "")
length(path_18)
```


## Testing

The forloop is not used, instead the `map()` function from the package `purrr` is used. However, the code exists for documentation.
```{r}
# testing for loop with url_printing
for(i in seq_along(urls_test)){
    download(urls_test[i], destination_test[i], mode="wb")
  print(urls_test[i])
}

# using map2() instead of a for loop
```

## live coding with fabio <3 & Download 18. BTD
```{r}
# fn + F2 :)
download

# creating sleep function
# take the function download() and set the sleep to 1.5 seconds
sleep_down <- function(...) {
  download(...)
  Sys.sleep(0.5)
}

# creating safely
# code exp: take the function sleep_down() and create with the function safely() a new function
#           because of the safely function, the loop will not interrupt, if it comes to errors
safe_download <- safely(sleep_down)

# downloading the documents for the 18. Bundestag
# code exp: map2() can use two arguments -> take the vector urls as the first argument 
#           and the vector destinations as the second argument
#           
map_results_18 <- map2(urls_18, path_18,
                    ~safe_download(.x, .y, mode ="wb"))



# converting list into two vectors as.character()
results_18 <- map(map_results_18, "result") %>% 
  as.character() 
error_18 <- map(map_results_18, "error") %>% 
  as.character()

# creating df
tibble(results_18, error_18)
```


## Download 19. BTD
```{r}
# checking urls & path
# IMPORTANT: check the last documents!
head(urls_19)
head(path_19)
tail(urls_19)
tail(path_19)

# downloading all documents for the 19. Bundestag (cut off: end of Nov 2018)
map_results_19 <- map2(urls_19, path_19,
                       ~safe_download(.x, .y, mode = "wb"))

# creating two vectors regarding record of errors again
results_19 <- map(map_results_19, "results") %>% 
  as.character()
error_19 <- map(map_results_19, "error") %>% 
  as.character()

# creating df again
tail(tibble(results_19, error_19))
```

```{r}
library(ggplot2)
library(ggthemes)
year_table <- structure(list(Year = c(2020L, 2021L, 2022L, NA), number = c(55L, 
81L, 187L, 3L), pct = c(0.168711656441718, 0.248466257668712, 
0.573619631901841, 0.00920245398773006)), class = c("tbl_df", 
"tbl", "data.frame"), row.names = c(NA, -4L))

ggplot(data = year_table, mapping = aes(x = Year, y = number)) +
  geom_col(fill= "darkslategray3") + 
  theme_economist() +
  ggtitle("Distribution of Applicants based on Class Year") +
  geom_text(data=year_table, aes(label=paste0(round(pct*100,1),"%"),
                                 y=number), size=4, vjust = -.5)
```

